# 论文笔记

## 光源估计

**(2022 AAAI) Rendering-Aware HDR Environment Map Prediction from a Single Image**

问题提出：

1. 从有限视野（FOV）LDR图像估计HDR全景照明图非常复杂（照明条件、表面材质、场景几何、相机参数）

2. 参数化的光照模型难以准确和充分估计全频率照明（SH解释高频能力弱，SG能表示高质量高光和镜面反射，但描述低频能力弱），直接估计全频率的HDR照明图效果差

解决方案：

1. 使用两阶段的框架从LDR FOV图像估计HDR全景照明图
2. 使用Transformer估计主光源的SG表示高频照明，用CNN估计二阶SH表示低频照明
3. 将估计的SG和SH参数转换为高斯照明图和漫射辐照度图（参数可视化），以两幅图作为先验，用GAN生成HDR全景照明图
4. 采用一个可微渲染层，将渲染损失也作为一个损失项监督GAN的生成

![The structure of SG Regression Module](D:\笔记\images\(2022 AAAI) Rendering-Aware HDR Environment Map Prediction from a Single Image1.png)

![The structure of SH Regression Module](D:\笔记\images\(2022 AAAI) Rendering-Aware HDR Environment Map Prediction from a Single Image2.png)

![The structure of the generative network](D:\笔记\images\(2022 AAAI) Rendering-Aware HDR Environment Map Prediction from a Single Image3.png)



**(2020 ECCV) Object-based Illumination Estimation with Rendering-aware Neural Networks**

问题提出：

1. 实际的AR应用中需要实时估计局部场景的照明
2. 从单个图像进行场景的逆渲染难以实现，需要简化照明模型和材质类型
3. 逆渲染的优化需要高计算成本，难以同时保证高精度和实时性能
4. 神经网络需要知道渲染的物理规则，分析物理渲染不适用于实时应用，漫反射和镜面反射规则不同，且与物体材质有关
5. 目前基于场景的估计方法，都是从场景（全景图）中包含的一块有限区域中的信息估计光照，区域中的内容量决定了估计光的质量
6. 前人训练端到端逆渲染网络，但只假设漫反射着色，并因为渲染器限制只能产生低分辨率EM

解决方案：

1. 提出一种从单个对象（物体）的RGBD外观及其周围局部区域的图像（FOV）估计整个场景的照明（HDR Environment Map），端到端直接估计HDR照明图
2. 仍使用基于物理的逆渲染，中间步骤使用深度学习进行加速，输入RGBD图像（可计算法线信息，辐照度图也由深度图计算），使用深度学习计算反射率、漫反射、镜面反射，并将漫反射着色转换为角度照明域（空间域转换为角度域），将镜面着色几何映射到其镜面方向，通过角度融合产生HDR EM
3. 使用物理规则可以将镜面反射等信息投影到照明方向
4. 使用递归卷积层考虑照明环境的时间相干性（连贯性）
5. 使用基于物理的逆渲染和神经网络结合，比纯基于学习的方法估计精度更高
6. 只从场景中单个对象（物体）的着色信息估计HDR EM，不依赖场景中的内容量，不对表面反射进行假设，作为基于场景的估计方法的补充

![Overview of system](D:\笔记\images\(2020 ECCV) Object-based Illumination Estimation with Rendering-aware Neural Networks1.png)

结论：

1. 具有高频照明的灯光（主灯光）比低频灯光（近似环境照明）更难估计
2. 基于场景的方法和基于对象的方法结合是一个未来的研究方向



















**idea**

1. CubeMap的粗糙度

2. 知道空间中两个点的CubeMap/球面高斯，在中间做插值

